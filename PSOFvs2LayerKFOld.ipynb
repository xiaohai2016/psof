{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptions\n",
    "This notebook runs simulation defined in the (older) paper: Shu-Li. Sun, “Multi-sensor optimal information fusion kalman filter with applications” Airospace Science and Technology 8 (2004)57-62. Available at http://www.paper.edu.cn/scholar/showpdf/MUT2UN2IOTD0MxeQh. This looks like to be an earlier edition of Sun's paper.\n",
    "\n",
    "We first reproduce the results defined in the paper. Then we replace the second layer with PSOF methods to compare the performance. It is shown that PSOF method achieves comparable performance as the method described in Sun's paper without the need for cross-covariance data calculation and communication.\n",
    "\n",
    "Note the $\\Sigma$ matrix from Sun's paper seems to be ill-conditioned initially, and I had to add $10^{-10}I_n$ to counter that issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation for two stage distributed Kalman filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Kalman filtering - Lemma 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_kalman(x_t_t, p_t_t, y_tplus1, m_phi, m_gamma, m_h, m_q, m_r):\n",
    "    \"\"\"\n",
    "    Given previous estimates & current measurement\n",
    "    to return updated estimates and Kalman gain\n",
    "    \"\"\"\n",
    "    i_n = np.identity(m_phi.shape[1])\n",
    "    x_tplus1_t = m_phi @ x_t_t\n",
    "    delta_tplus1 = y_tplus1 - m_h @ x_tplus1_t\n",
    "    p_tplus1_t = m_phi @ p_t_t @ m_phi.T + m_gamma @ m_q @ m_gamma.T\n",
    "    k_tplus1 = p_tplus1_t @ m_h.T @ np.linalg.inv(m_h @ p_tplus1_t @ m_h.T + m_r)\n",
    "    x_tplus1_tplus1 = x_tplus1_t + k_tplus1 @ delta_tplus1\n",
    "    p_tplus1_tplus1 = (i_n - k_tplus1 @ m_h) @ p_tplus1_t\n",
    "    return x_tplus1_tplus1, p_tplus1_tplus1, k_tplus1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-covariances between tracks - Lemma 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_covariance(phi, gamma, h_i, h_j, q, k_i, k_j, p_t_t):\n",
    "    \"\"\"\n",
    "    Given modeling parameters, Kalman gains and previous cross covariances\n",
    "    to update the new cross covariances\n",
    "    \"\"\"\n",
    "    i_n = np.identity(phi.shape[1])\n",
    "    p_tplus1_tplus1 = (i_n - k_i @ h_i) @ \\\n",
    "                      (phi @ p_t_t @ phi.T + gamma @ q @ gamma.T) @ \\\n",
    "                      (i_n - k_j @ h_j).T\n",
    "    return p_tplus1_tplus1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second stage optimal fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Matrix coefficients for fusion - Theorem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opti_fusion_matrix(p_ijs, x_is):\n",
    "    \"\"\"\n",
    "    Given all covariances and cross-covariances, and multiple state estimates\n",
    "    to return the mixing coefficient matrixes, fused results and covariance\n",
    "    \"\"\"\n",
    "    l = round(math.sqrt(len(p_ijs)))\n",
    "    n = p_ijs[0].shape[1]\n",
    "    e = np.concatenate([np.identity(n) for _ in range(l)])\n",
    "    Sigma = np.concatenate([np.concatenate(p_ijs[i*l:(i+1)*l], axis=1) for i in range(l)])\n",
    "    Sigma_inv = np.linalg.inv(Sigma + 1e-10 * np.identity(n*l))\n",
    "    P_0 = np.linalg.inv(e.T @ Sigma_inv @ e)\n",
    "    A_bar = Sigma_inv @ e @ P_0\n",
    "    x_0 = A_bar.T @ np.concatenate(x_is)\n",
    "    return A_bar, x_0, P_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vector coefficients for fusion - Theorem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opti_fusion_vector(p_ijs, x_is):\n",
    "    \"\"\"\n",
    "    Given all covariances and cross-covariances, and multiple state estimates\n",
    "    to return the mixing coefficient vectors, fused results and covariance\n",
    "    \"\"\"\n",
    "    l = round(math.sqrt(len(p_ijs)))\n",
    "    n = p_ijs[0].shape[1]\n",
    "    e = np.concatenate([np.identity(n) for _ in range(l)])\n",
    "    P_ij_nl_nl = np.concatenate([np.concatenate(p_ijs[i*l:(i+1)*l], axis=1) for i in range(l)])\n",
    "    e_exp = np.concatenate([e.T for _ in range(l)])\n",
    "    Sigma = P_ij_nl_nl * e_exp\n",
    "    Sigma_inv = np.linalg.inv(Sigma + 1e-10 * np.identity(n*l))\n",
    "    \n",
    "    temp = np.linalg.inv(e.T @ Sigma_inv @ e)\n",
    "    A_bar = Sigma_inv @ e @ temp\n",
    "    x_0 = A_bar.T @ np.concatenate(x_is)\n",
    "    P_0 = temp @ e.T @ Sigma_inv @ P_ij_nl_nl @ Sigma_inv @ e @ temp\n",
    "    return A_bar, x_0, P_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scalar coefficients for fusion - Theorem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opti_fusion_scalar(p_ijs, x_is):\n",
    "    \"\"\"\n",
    "    Given all covariances and cross-covariances, and multiple state estimates\n",
    "    to return the mixing coefficient scalars, fused results and covariance\n",
    "    \"\"\"\n",
    "    l = round(math.sqrt(len(p_ijs)))\n",
    "    n = p_ijs[0].shape[1]\n",
    "    e = np.full((l,1), 1.0, dtype=float)\n",
    "    P_ij_nl_nl = np.concatenate([np.concatenate(p_ijs[i*l:(i+1)*l], axis=1) for i in range(l)])\n",
    "    Sigma = np.concatenate([np.concatenate([np.array([[np.trace(p_ijs[i*l + j])]], dtype=float) \\\n",
    "                                            for j in range(l)], axis=1) for i in range(l)])\n",
    "    Sigma_inv = np.linalg.inv(Sigma + 1e-10 * np.identity(l))\n",
    "    temp = np.linalg.inv(e.T @ Sigma_inv @ e)\n",
    "    A_bar = Sigma_inv @ e @ temp\n",
    "    x_0 = np.concatenate(x_is, axis=1) @ A_bar\n",
    "    A_bar_exp = np.concatenate([A_bar[i, 0] * np.identity(n)for i in range(l)], axis=1)\n",
    "    P_0 = A_bar_exp @ P_ij_nl_nl @ A_bar_exp.T\n",
    "    return A_bar, x_0, P_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation for Sun's paper\n",
    "To reproduce the simulation results in Sun's paper. In Table 1 of Sun's paper, its index data seemed to be off by one. For comparison purpose, we inherited this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "\n",
    "T = 0.01\n",
    "sigma_w_sqr = 1.0\n",
    "sigma_v1_sqr = 8.0\n",
    "sigma_v2_sqr = 15.0\n",
    "sigma_v3_sqr = 20.0\n",
    "\n",
    "H_1 = np.array([[1.0, 0.0, 0.0]], np.float)\n",
    "H_2 = np.array([[0.0, 1.0, 0.0]], np.float)\n",
    "H_3 = np.array([[0.0, 0.0, 1.0]], np.float)\n",
    "y_1 = np.array([1.0], np.float)\n",
    "y_2 = np.array([1.0], np.float)\n",
    "y_3 = np.array([1.0], np.float)\n",
    "\n",
    "Phi = np.array([[1.0, T, T * T / 2.0], [0.0, 1.0, T], [0.0, 0.0, 1.0]], np.float)\n",
    "Gamma = np.array([[0.0], [0.0], [1.0]], np.float)\n",
    "\n",
    "# Distributed fusion\n",
    "m_q = np.full((1,1), sigma_w_sqr)\n",
    "m_r_1 = np.full((1,1), sigma_v1_sqr)\n",
    "m_r_2 = np.full((1,1), sigma_v2_sqr)\n",
    "m_r_3 = np.full((1,1), sigma_v3_sqr)\n",
    "m_r = np.array([[sigma_v1_sqr, 0.0, 0.0], [0.0, sigma_v2_sqr, 0.0], [0.0, 0.0, sigma_v3_sqr]], dtype=float)\n",
    "\n",
    "iterations_to_print = set([10, 50, 100, 150, 200])\n",
    "\n",
    "for tag in ('u', 'm', 'v', 's'):\n",
    "    x_0 = np.zeros((3,1), dtype=float)\n",
    "    x_1 = x_2 = x_3 = x_0\n",
    "    P_0 = 0.1 * np.identity(3)\n",
    "    P_1_2 = P_1_3 = P_2_1 = P_2_3 = P_3_1 = P_3_2 = P_0\n",
    "    P_1 = P_2 = P_3 = P_0\n",
    "    \n",
    "    for i in range(200):\n",
    "        \n",
    "        # Local Kalman filtering for channel 1\n",
    "        x_1, P_1, K_1 = local_kalman(x_1, P_1, y_1, Phi, Gamma, H_1, m_q, m_r_1)\n",
    "        # Local Kalman filtering for channel 2\n",
    "        x_2, P_2, K_2 = local_kalman(x_2, P_2, y_2, Phi, Gamma, H_2, m_q, m_r_2)\n",
    "        # Local Kalman filtering for channel 3\n",
    "        x_3, P_3, K_3 = local_kalman(x_3, P_3, y_3, Phi, Gamma, H_3, m_q, m_r_3)\n",
    "        if tag == 'u':\n",
    "            # No second stage data fusion\n",
    "            if (i+2) in iterations_to_print:\n",
    "                print(f\"Iteration: {(i+2)}  tr(P_1(t|t)): {np.trace(P_1)}  tr(P_2(t|t)): {np.trace(P_2)}  tr(P_3(t|t)): {np.trace(P_3)}\")\n",
    "        else:\n",
    "            # Second stage data fusion\n",
    "            # Cross-covariance updates\n",
    "            P_1_2 = get_cross_covariance(Phi, Gamma, H_1, H_2, m_q, K_1, K_2, P_1_2)\n",
    "            P_1_3 = get_cross_covariance(Phi, Gamma, H_1, H_3, m_q, K_1, K_3, P_1_3)\n",
    "            P_2_3 = get_cross_covariance(Phi, Gamma, H_2, H_3, m_q, K_2, K_3, P_2_3)\n",
    "            P_2_1 = P_1_2.T\n",
    "            P_3_1 = P_1_3.T\n",
    "            P_3_2 = P_2_3.T\n",
    "            if tag == 'm':\n",
    "                _, x_0, P_0 = get_opti_fusion_matrix([P_1, P_1_2, P_1_3, P_2_1, P_2, P_2_3, P_3_1, P_3_2, P_3], [x_1, x_2, x_3])\n",
    "            elif tag == 'v':\n",
    "                _, x_0, P_0 = get_opti_fusion_vector([P_1, P_1_2, P_1_3, P_2_1, P_2, P_2_3, P_3_1, P_3_2, P_3], [x_1, x_2, x_3])\n",
    "            else:\n",
    "                _, x_0, P_0 = get_opti_fusion_scalar([P_1, P_1_2, P_1_3, P_2_1, P_2, P_2_3, P_3_1, P_3_2, P_3], [x_1, x_2, x_3])\n",
    "            if (i+2) in iterations_to_print:\n",
    "                print(f\"Iteration: {(i+2)}  tr(P_0^{tag}(t|t)): {np.trace(P_0)}\")\n",
    "            x_1 = x_2 = x_3 = x_0\n",
    "            P_1 = P_2 = P_3 = P_0\n",
    "\n",
    "# Centralized fusion\n",
    "x_0 = np.zeros((3,1), dtype=float)\n",
    "P_0 = 0.1 * np.identity(3)\n",
    "y = np.zeros((1,3))\n",
    "H = np.concatenate((np.concatenate((H_1, H_2)), H_3))\n",
    "for i in range(200):\n",
    "    x_0, P_0, _ = local_kalman(x_0, P_0, y, Phi, Gamma, H, m_q, m_r)\n",
    "    if (i+2) in iterations_to_print:\n",
    "        print(f\"Iteration: {i+2}   tr(P_c(t|t)): {np.trace(P_0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation for two stage distributed filtering with PSOF as the second stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSOF codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def func_constant_step_size(sub_gradient, iteration, diff_from_best_estimate):\n",
    "    return 0.0004\n",
    "\n",
    "def func_constant_step_length(sub_gradient, iteration, diff_from_best_estimate):\n",
    "    global csl_initial_norm\n",
    "    N,M,_ = sub_gradient.shape\n",
    "    norm = 0\n",
    "    for i in range(N):\n",
    "        norm += np.trace(np.matmul(sub_gradient[i], np.transpose(sub_gradient[i])))\n",
    "    return 0.002 / np.sqrt(norm)\n",
    "        \n",
    "def func_square_summable_not_summable(sub_gradient, iteration, diff_from_best_estimate):\n",
    "    return 3.0 / (iteration + 1)\n",
    "\n",
    "def func_not_summable_diminishing_step_size(sub_gradient, iteration, diff_from_best_estimate):\n",
    "    return 0.035 / np.sqrt(iteration + 1)\n",
    "\n",
    "def func_not_summable_diminishing_step_length(sub_gradient, iteration, diff_from_best_estimate):\n",
    "    global nsdsl_initial_norm\n",
    "    N,M,_ = sub_gradient.shape\n",
    "    norm = 0\n",
    "    for i in range(N):\n",
    "        norm += np.trace(np.matmul(sub_gradient[i], np.transpose(sub_gradient[i])))\n",
    "    return 0.19 / np.sqrt(norm * (iteration + 1))\n",
    "\n",
    "def func_polyak_with_estimate(sub_gradient, iteration, diff_from_best_estimate):\n",
    "    global polyak_initial_norm\n",
    "    N,M,_ = sub_gradient.shape\n",
    "    norm = 0\n",
    "    for i in range(N):\n",
    "        norm += np.trace(np.matmul(sub_gradient[i], np.transpose(sub_gradient[i])))\n",
    "    return (0.035 * norm / np.sqrt(iteration + 1) + diff_from_best_estimate) / norm\n",
    "\n",
    "# Projected Subgradient Method\n",
    "\n",
    "# Usage:\n",
    "#   a_i, mse, v_opt, v_ij_opt = gdof (\n",
    "#    N, M, \n",
    "#    joint_covariance, \n",
    "#    unknown_index_matrix)\n",
    "#\n",
    "# Inputs:\n",
    "#   N - the input measurement count\n",
    "#   M - the input measurement dimension\n",
    "#   joint_covariance - the joint covariance matrix\n",
    "#       for the all the measurements. It's a 4-d\n",
    "#       tensor, with the first two dimensions\n",
    "#       referring to the measurements and the last\n",
    "#       two dimensions referring to the measurement\n",
    "#       components. For unknown cross-correlation\n",
    "#       matrices, the values are not used.\n",
    "#   unknown_index_matrix - a bool numpy array.\n",
    "#       the element of the matrix at\n",
    "#       location (i,j) is set to be one if V_ij is unknown.\n",
    "#       otherwise it is set to be zero.\n",
    "#\n",
    "# Outputs:\n",
    "# . a_i - the matrix weights, a tensor of 3d, with the first\n",
    "# .       dimension index being the measurement index\n",
    "# . mse - the resulting mean square error\n",
    "# . v_opt - the estimate covariance\n",
    "#   v_ij_opt - the maximizing cross correlation matrix at (i,j)\n",
    "def PSOF(N, M, joint_covariance, unknown_index_matrix, step_func=func_constant_step_size, max_iteration=12000):\n",
    "    assert (N, N, M, M) == joint_covariance.shape\n",
    "    assert (N, N) == unknown_index_matrix.shape\n",
    "    V = joint_covariance\n",
    "    B = np.zeros((N, M, M), dtype=np.float32)\n",
    "    Lambda_inv_sqrt = np.zeros((N,M), dtype=np.float32)\n",
    "    U = np.zeros((N, M, M), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        Lambda_inv_sqrt[i], U[i] = np.linalg.eigh(joint_covariance[i, i])\n",
    "        Lambda_inv_sqrt[i] = np.reciprocal(np.sqrt(Lambda_inv_sqrt[i]))\n",
    "        B[i] = np.matmul(np.diag(Lambda_inv_sqrt[i]), np.transpose(U[i]))\n",
    "    \n",
    "    V_prime = np.zeros((N, N, M, M), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j and (not unknown_index_matrix[i, j]):\n",
    "                V_prime[i, j] = np.matmul(np.diag(Lambda_inv_sqrt[i]), np.transpose(U[i]))\n",
    "                V_prime[i, j] = np.matmul(V_prime[i, j], V[i, j])\n",
    "                V_prime[i, j] = np.matmul(V_prime[i, j], U[j])\n",
    "                V_prime[i, j] = np.matmul(V_prime[i, j], np.diag(Lambda_inv_sqrt[j]))\n",
    "    \n",
    "    Sigma = np.zeros((M, M), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        Sigma = Sigma + np.linalg.inv(V[i, i])\n",
    "    Sigma_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "    # initial A_prime values\n",
    "    A_prime = np.zeros((N, M, M), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        A_prime[i] = np.matmul(U[i], np.diag(np.reciprocal(Lambda_inv_sqrt[i]))) / N\n",
    "\n",
    "    epislon = 1.0e-12\n",
    "    mse = np.finfo(np.float32).max\n",
    "    mse_iteration = []\n",
    "    mse_best = np.finfo(np.float32).max\n",
    "    last_mse_diff = 0\n",
    "    A_prime_best = np.zeros((N, M, M), dtype=np.float32)\n",
    "    for iteration in range(max_iteration):\n",
    "\n",
    "        # Get SVD of A[j]^T A[i]\n",
    "        C = np.zeros((N, N, M, M), dtype=np.float32)\n",
    "        D = np.zeros((N, N, M, M), dtype=np.float32)\n",
    "        Lambda_ij = np.zeros((N, N, M), dtype=np.float32)\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i != j and unknown_index_matrix[i, j]:\n",
    "                    C[i, j], Lambda_ij[i, j], D[i, j] = np.linalg.svd(np.matmul(np.transpose(A_prime[j]), A_prime[i]))\n",
    "                    D[i, j] = np.transpose(D[i, j]) # convention of python linalg library\n",
    "                    \n",
    "        # compute subgradients\n",
    "        dA_prime = np.zeros((N, M, M), np.float32)\n",
    "        for i in range(N):\n",
    "            dA_prime[i] = A_prime[i]\n",
    "            for j in range(N):\n",
    "                if j != i:\n",
    "                    if unknown_index_matrix[i, j]:\n",
    "                        dA_prime[i] = dA_prime[i] + np.matmul(np.matmul(A_prime[j], C[i, j]), np.transpose(D[i, j]))\n",
    "                    else:\n",
    "                        dA_prime[i] = dA_prime[i] + np.matmul(A_prime[j], np.transpose(V_prime[i, j]))\n",
    "            dA_prime[i] = dA_prime[i] * 2.0\n",
    "\n",
    "        # apply step size & subgradient\n",
    "        step = step_func(dA_prime, iteration, last_mse_diff)\n",
    "        for i in range(N):\n",
    "            A_prime[i] = A_prime[i] - dA_prime[i] * step\n",
    "            \n",
    "        # project onto the constraint hyperplanes\n",
    "        A_prime_dot_B = np.zeros((M, M), np.float32)\n",
    "        for i in range(N):\n",
    "            A_prime_dot_B = A_prime_dot_B + np.matmul(A_prime[i], B[i])\n",
    "        A_prime_dot_B_Sigma_inv = np.matmul(np.eye(M, dtype=np.float32) - A_prime_dot_B, Sigma_inv)\n",
    "        for i in range(N):\n",
    "            A_prime[i] = A_prime[i] + np.matmul(A_prime_dot_B_Sigma_inv, np.transpose(B[i]))\n",
    "\n",
    "        # compute mse\n",
    "        mse_prime = 0.0\n",
    "        for i in range(N):\n",
    "            mse_prime = mse_prime + np.trace(np.matmul(np.transpose(A_prime[i]), A_prime[i]))\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i != j:\n",
    "                    if unknown_index_matrix[i, j]:\n",
    "                        _, sigmas, _ = np.linalg.svd(np.matmul(np.transpose(A_prime[j]), A_prime[i]))\n",
    "                        mse_prime = mse_prime + np.sum(sigmas)\n",
    "                    else:\n",
    "                        mse_prime = mse_prime + np.trace(np.matmul(np.matmul(A_prime[i], V_prime[i, j]), np.transpose(A_prime[j])))\n",
    "        \n",
    "        mse_iteration.append(mse_prime)\n",
    "        #print('mse: ', mse_prime, mse_best, sigmas, A_prime)\n",
    "        if mse_prime < mse_best:\n",
    "            mse_best = mse_prime\n",
    "            A_prime_best = A_prime\n",
    "            last_mse_diff = 0\n",
    "        last_mse_diff = mse_prime - mse_best\n",
    "    \n",
    "    A = np.zeros((N, M, M), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        A[i] = np.matmul(np.matmul(A_prime_best[i], np.diag(Lambda_inv_sqrt[i])), np.transpose(U[i]))\n",
    "    V_ij_opt = np.zeros((N, N, M, M), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j and unknown_index_matrix[i, j]:\n",
    "                C_ij, Lambda_ij, D_ij = np.linalg.svd(np.matmul(np.transpose(A_prime_best[j]), A_prime_best[i]))\n",
    "                part_left = np.matmul(U[i], np.diag(np.reciprocal(Lambda_inv_sqrt[i])))\n",
    "                part_middle = np.matmul(np.transpose(D_ij), np.transpose(C_ij))\n",
    "                part_right = np.matmul(np.diag(np.reciprocal(Lambda_inv_sqrt[j])), np.transpose(U[j]))\n",
    "                V_ij_opt[i, j] = np.matmul(np.matmul(part_left, part_middle), part_right)\n",
    "    V_opt = np.zeros((M, M), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j and unknown_index_matrix[i, j]:\n",
    "                V_opt = V_opt + np.matmul(np.matmul(A[i], V_ij_opt[i, j]), np.transpose(A[j]))\n",
    "            else:\n",
    "                V_opt = V_opt + np.matmul(np.matmul(A[i], V[i, j]), np.transpose(A[j]))\n",
    "    \n",
    "    return A, mse_best, V_opt, V_ij_opt, mse_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "\n",
    "T = 0.01\n",
    "sigma_w_sqr = 1.0\n",
    "sigma_v1_sqr = 8.0\n",
    "sigma_v2_sqr = 15.0\n",
    "sigma_v3_sqr = 20.0\n",
    "\n",
    "H_1 = np.array([[1.0, 0.0, 0.0]], np.float)\n",
    "H_2 = np.array([[0.0, 1.0, 0.0]], np.float)\n",
    "H_3 = np.array([[0.0, 0.0, 1.0]], np.float)\n",
    "y_1 = np.array([1.0], np.float)\n",
    "y_2 = np.array([1.0], np.float)\n",
    "y_3 = np.array([1.0], np.float)\n",
    "\n",
    "Phi = np.array([[1.0, T, T * T / 2.0], [0.0, 1.0, T], [0.0, 0.0, 1.0]], np.float)\n",
    "Gamma = np.array([[0.0], [0.0], [1.0]], np.float)\n",
    "\n",
    "# Distributed fusion\n",
    "m_q = np.full((1,1), sigma_w_sqr)\n",
    "m_r_1 = np.full((1,1), sigma_v1_sqr)\n",
    "m_r_2 = np.full((1,1), sigma_v2_sqr)\n",
    "m_r_3 = np.full((1,1), sigma_v3_sqr)\n",
    "\n",
    "iterations_to_print = set([10, 50, 100, 150, 200])\n",
    "\n",
    "unknown_index_matrix = np.array([[False, True, True], [True, False, True], [True, True, False]], dtype=bool)\n",
    "N = 3\n",
    "M = 3\n",
    "\n",
    "x_0 = np.zeros((3,1), dtype=float)\n",
    "x_1 = x_2 = x_3 = x_0\n",
    "P_0 = 0.1 * np.identity(3)\n",
    "P_1 = P_2 = P_3 = P_0\n",
    "\n",
    "for i in range(200):\n",
    "\n",
    "    # Local Kalman filtering for channel 1\n",
    "    x_1, P_1, K_1 = local_kalman(x_1, P_1, y_1, Phi, Gamma, H_1, m_q, m_r_1)\n",
    "    # Local Kalman filtering for channel 2\n",
    "    x_2, P_2, K_2 = local_kalman(x_2, P_2, y_2, Phi, Gamma, H_2, m_q, m_r_2)\n",
    "    # Local Kalman filtering for channel 3\n",
    "    x_3, P_3, K_3 = local_kalman(x_3, P_3, y_3, Phi, Gamma, H_3, m_q, m_r_3)\n",
    "    # Second stage data fusion with PSOF\n",
    "    joint_covariance = np.array([[P_1, P_1, P_1],[P_2, P_2, P_2], [P_3, P_3, P_3]], np.float32)\n",
    "    _, _, P_0, _, _ = PSOF(N, M, joint_covariance, unknown_index_matrix)\n",
    "    if (i+1) in iterations_to_print:\n",
    "        print(f\"Iteration: {(i+1)}\")\n",
    "        print(f\"  tr(P_0^psof(t|t)): {np.trace(P_0)}\")\n",
    "    P_1 = P_2 = P_3 = P_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
